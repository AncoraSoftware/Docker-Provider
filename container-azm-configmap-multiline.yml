kind: ConfigMap
apiVersion: v1
data:
  schema-version:
    #string.used by agent to parse config. supported versions are {v1}. Configs with other schema versions will be rejected by the agent.
    v1
  config-version:
    #string.used by customer to keep track of this config file's version in their source control/repository (max allowed 10 chars, other chars will be truncated)
    ver1
  log-data-collection-settings: |-
    # Log data collection settings
    # Any errors related to config map settings can be found in the KubeMonAgentEvents table in the Log Analytics workspace that the cluster is sending data to.

    [log_collection_settings]
       [log_collection_settings.stdout]
          # In the absense of this configmap, default value for enabled is true
          enabled = true
          # exclude_namespaces setting holds good only if enabled is set to true
          # kube-system log collection is disabled by default in the absence of 'log_collection_settings.stdout' setting. If you want to enable kube-system, remove it from the following setting.
          # If you want to continue to disable kube-system log collection keep this namespace in the following setting and add any other namespace you want to disable log collection to the array.
          # In the absense of this configmap, default value for exclude_namespaces = ["kube-system"]
          # exclude_namespaces = ["default","kube-node-lease","kube-public","kube-system", "openshift", "openshift-apiserver", "openshift-apiserver-operator", "openshift-authentication", "openshift-authentication-operator", "openshift-azure-logging", "openshift-azure-operator", "openshift-azure-routefix", "openshift-cloud-credential-operator", "openshift-cluster-machine-approver", "openshift-cluster-node-tuning-operator", "openshift-cluster-samples-operator", "openshift-cluster-storage-operator", "openshift-cluster-version", "openshift-config", "openshift-config-managed", "openshift-console", "openshift-console-operator", "openshift-controller-manager", "openshift-controller-manager-operator", "openshift-dns", "openshift-dns-operator", "openshift-etcd", "openshift-etcd-operator", "openshift-image-registry", "openshift-infra", "openshift-ingress", "openshift-ingress-operator", "openshift-insights", "openshift-kni-infra", "openshift-kube-apiserver", "openshift-kube-controller-manager", "openshift-kube-controller-manager-operator", "openshift-kube-scheduler", "openshift-kube-scheduler-operator", "openshift-kube-storage-version-migrator", "openshift-kube-storage-version-migrator-operator", "openshift-logging", "openshift-machine-api", "openshift-machine-config-operator", "openshift-marketplace", "openshift-monitoring", "openshift-multus", "openshift-network-operator", "openshift-node", "openshift-openstack-infra", "openshift-operator-lifecycle-manager", "openshift-operators", "openshift-ovirt-infra", "openshift-sdn", "openshift-service-ca", "openshift-service-ca-operator", "openshift-service-catalog-apiserver-operator", "openshift-service-catalog-controller-manager-operator", "openshift-user-workload-monitoring", "openshift-vsphere-infra"]
          exclude_namespaces = ["openshift"]

       [log_collection_settings.stderr]
          # Default value for enabled is true
          enabled = true
          # exclude_namespaces setting holds good only if enabled is set to true
          # kube-system log collection is disabled by default in the absence of 'log_collection_settings.stderr' setting. If you want to enable kube-system, remove it from the following setting.
          # If you want to continue to disable kube-system log collection keep this namespace in the following setting and add any other namespace you want to disable log collection to the array.
          # In the absense of this cofigmap, default value for exclude_namespaces = ["kube-system"]
          # exclude_namespaces = ["default","kube-node-lease","kube-public","kube-system", "openshift", "openshift-apiserver", "openshift-apiserver-operator", "openshift-authentication", "openshift-authentication-operator", "openshift-azure-logging", "openshift-azure-operator", "openshift-azure-routefix", "openshift-cloud-credential-operator", "openshift-cluster-machine-approver", "openshift-cluster-node-tuning-operator", "openshift-cluster-samples-operator", "openshift-cluster-storage-operator", "openshift-cluster-version", "openshift-config", "openshift-config-managed", "openshift-console", "openshift-console-operator", "openshift-controller-manager", "openshift-controller-manager-operator", "openshift-dns", "openshift-dns-operator", "openshift-etcd", "openshift-etcd-operator", "openshift-image-registry", "openshift-infra", "openshift-ingress", "openshift-ingress-operator", "openshift-insights", "openshift-kni-infra", "openshift-kube-apiserver", "openshift-kube-controller-manager", "openshift-kube-controller-manager-operator", "openshift-kube-scheduler", "openshift-kube-scheduler-operator", "openshift-kube-storage-version-migrator", "openshift-kube-storage-version-migrator-operator", "openshift-logging", "openshift-machine-api", "openshift-machine-config-operator", "openshift-marketplace", "openshift-monitoring", "openshift-multus", "openshift-network-operator", "openshift-node", "openshift-openstack-infra", "openshift-operator-lifecycle-manager", "openshift-operators", "openshift-ovirt-infra", "openshift-sdn", "openshift-service-ca", "openshift-service-ca-operator", "openshift-service-catalog-apiserver-operator", "openshift-service-catalog-controller-manager-operator", "openshift-user-workload-monitoring", "openshift-vsphere-infra"]
          exclude_namespaces = ["openshift"]

       [log_collection_settings.env_var]
          # In the absense of this configmap, default value for enabled is true
          enabled = true
       [log_collection_settings.enrich_container_logs]
          # In the absense of this configmap, default value for enrich_container_logs is false
          enabled = false
          # When this is enabled (enabled = true), every container log entry (both stdout & stderr) will be enriched with container Name & container Image
       [log_collection_settings.collect_all_kube_events]
          # In the absense of this configmap, default value for collect_all_kube_events is false
          # When the setting is set to false, only the kube events with !normal event type will be collected
          enabled = true
          # When this is enabled (enabled = true), all kube events including normal events will be collected

       [log_collection_settings.stitch_multiline_logs]
          # In the absense of this configmap, default value for stitch_multiline_logs is false
          # When the setting is set to true, log lines which do not start with a timestamp are appended to the previous log line
          # this is usefull for combining logical events (like exception stack traces) into a single line
          enabled = false

          #TODO: turn on by default with containerlog v2 (validate with Sahil just to make sure)
          #TODO: Log line collomn can only be 16k (in LA). What protection is there to prevent infinite appending? (LA will drop lines too long)
          #TODO: look at fluent-bit processors to strip containerd header

       [log_collection_settings.schema]
          containerlog_schema_version = "v2"
        
  prometheus-data-collection-settings: |-
    # Custom Prometheus metrics data collection settings
    [prometheus_data_collection_settings.cluster]
        # Cluster level scrape endpoint(s). These metrics will be scraped from agent's Replicaset (singleton)
        # Any errors related to prometheus scraping can be found in the KubeMonAgentEvents table in the Log Analytics workspace that the cluster is sending data to.

        #Interval specifying how often to scrape for metrics. This is duration of time and can be specified for supporting settings by combining an integer value and time unit as a string value. Valid time units are ns, us (or µs), ms, s, m, h.
        interval = "60s"

        ## Uncomment the following settings with valid string arrays for prometheus scraping
        #fieldpass = ["metric_to_pass1", "metric_to_pass12"]

        #fielddrop = ["metric_to_drop"]

        # An array of urls to scrape metrics from.
        #  urls = ["http://127.0.0.1:2020/api/v1/metrics/prometheus"]

        # An array of Kubernetes services to scrape metrics from.
        # kubernetes_services = ["http://my-service-dns.my-namespace:9102/metrics"]

        # When monitor_kubernetes_pods = true, replicaset will scrape Kubernetes pods for the following prometheus annotations:
        # - prometheus.io/scrape: Enable scraping for this pod
        # - prometheus.io/scheme: If the metrics endpoint is secured then you will need to
        #     set this to `https` & most likely set the tls config.
        # - prometheus.io/path: If the metrics path is not /metrics, define it with this annotation.
        # - prometheus.io/port: If port is not 9102 use this annotation
        monitor_kubernetes_pods = true

        ## Restricts Kubernetes monitoring to namespaces for pods that have annotations set and are scraped using the monitor_kubernetes_pods setting.
        ## This will take effect when monitor_kubernetes_pods is set to true
        ##   ex: monitor_kubernetes_pods_namespaces = ["default1", "default2", "default3"]
        # monitor_kubernetes_pods_namespaces = ["default1"]

    [prometheus_data_collection_settings.node]
        # Node level scrape endpoint(s). These metrics will be scraped from agent's DaemonSet running in every node in the cluster
        # Any errors related to prometheus scraping can be found in the KubeMonAgentEvents table in the Log Analytics workspace that the cluster is sending data to.

        #Interval specifying how often to scrape for metrics. This is duration of time and can be specified for supporting settings by combining an integer value and time unit as a string value. Valid time units are ns, us (or µs), ms, s, m, h.
        interval = "10s"

        ## Uncomment the following settings with valid string arrays for prometheus scraping

        # An array of urls to scrape metrics from. $NODE_IP (all upper case) will substitute of running Node's IP address
        urls = ["http://127.0.0.1:2020/api/v1/metrics/prometheus", "http://localhost:4200"]

        #fieldpass = ["metric_to_pass1", "metric_to_pass12"]

        #fielddrop = ["metric_to_drop"]

  metric_collection_settings: |-
    # Metrics collection settings for metrics sent to Log Analytics and MDM
    [metric_collection_settings.collect_kube_system_pv_metrics]
      # In the absense of this configmap, default value for collect_kube_system_pv_metrics is false
      # When the setting is set to false, only the persistent volume metrics outside the kube-system namespace will be collected
      enabled = false
      # When this is enabled (enabled = true), persistent volume metrics including those in the kube-system namespace will be collected

  alertable-metrics-configuration-settings: |-
    # Alertable metrics configuration settings for container resource utilization
    [alertable_metrics_configuration_settings.container_resource_utilization_thresholds]
        # The threshold(Type Float) will be rounded off to 2 decimal points
        # Threshold for container cpu, metric will be sent only when cpu utilization exceeds or becomes equal to the following percentage
        container_cpu_threshold_percentage = 95.0
        # Threshold for container memoryRss, metric will be sent only when memory rss exceeds or becomes equal to the following percentage
        container_memory_rss_threshold_percentage = 95.0
        # Threshold for container memoryWorkingSet, metric will be sent only when memory working set exceeds or becomes equal to the following percentage
        container_memory_working_set_threshold_percentage = 95.0

    # Alertable metrics configuration settings for persistent volume utilization
    [alertable_metrics_configuration_settings.pv_utilization_thresholds]
        # Threshold for persistent volume usage bytes, metric will be sent only when persistent volume utilization exceeds or becomes equal to the following percentage
        pv_usage_threshold_percentage = 60.0
  integrations: |-
    [integrations.azure_network_policy_manager]
        collect_basic_metrics = false
        collect_advanced_metrics = false
metadata:
  name: container-azm-ms-agentconfig
  namespace: kube-system
